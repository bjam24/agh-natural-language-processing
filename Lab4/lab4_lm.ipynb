{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8553e1-5e6f-476a-b7c2-d7f8f679dadb",
   "metadata": {},
   "source": [
    "# NLP Lab4 - Language modelling\n",
    "\n",
    "**Author: Bartłomiej Jamiołkowski**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f3c46-4bb7-455f-8fec-b0ac1d84640b",
   "metadata": {},
   "source": [
    "The exercise shows how a language model may be used to solve word-prediction tasks and to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa14195-7783-4177-95a9-b332e352abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from termcolor import colored\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec3e22b-c9b6-4c19-9d71-932cd66c8b77",
   "metadata": {},
   "source": [
    "## Tasks 1 - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8618bd-0a46-490f-a43b-4381e9fd6890",
   "metadata": {},
   "source": [
    "Read the documentation of [Language modelling in the Transformers](https://huggingface.co/transformers/task_summary.html#language-modeling) library.\n",
    "\n",
    "Download three [Polish models](https://huggingface.co/models?filter=pl) from the Huggingface repository. These should be regular language models, which were not fine-tuned. E.g. `HerBERT` and `papuGaPT2` are good examples. You can also try using Bielik for that, but make sure you are using the model via Transformers API, not GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297c9940-8c6a-4ae7-a3a7-6a45a7fdbe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "twhin_bert_fill_mask = pipeline(task = 'fill-mask', model = 'Twitter/twhin-bert-base')\n",
    "herbert_base_fill_mask = pipeline(task = 'fill-mask', model = 'allegro/herbert-base-cased')\n",
    "xlm_roberta_fill_mask = pipeline(task = 'fill-mask', model = 'FacebookAI/xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89717e69-2f33-4b23-a268-4921e2d09efe",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c1b43-b7ff-4603-8ae4-6b2a02aae3a3",
   "metadata": {},
   "source": [
    "Devise a method to test if the langage model understands Polish cases. E.g. testing for *nominal case* could be expressed as \"Warszawa to największe `[MASK]`\", and the masked word should be in nominative case. Create sentences for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c278a5b1-a297-44a9-a13e-9fe2d2d36657",
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_cases_sentences_dict = {\n",
    "    'nominative': 'Warszawa to największe <mask>.',\n",
    "    'genitive': 'Brakuje mi smaku słodkiego <mask> w mojej herbacie.',\n",
    "    'dative': 'Daję napiwek uprzejmemu <mask> w restauracji.',\n",
    "    'accusative': 'Zbudowałem mały <mask> na plaży.',\n",
    "    'instrumental': 'Piszę nowym <mask>, który wczoraj kupiłem.',\n",
    "    'locative': 'Czytałem o ciekawym <mask> w gazecie.',\n",
    "    'vocative': 'Mądry <mask>, wysłuchaj moich słów!'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05129f82-2c85-4487-adb9-37d4d8276943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models_topic_understanding(model_list, sentences_dict: dict, k: int) -> None:\n",
    "    for model in model_list:\n",
    "        print(f\"{'-' * 45}\\nModel: {model.model.config._name_or_path.split('/')[1]}\\n{'-' * 45}\")\n",
    "\n",
    "        model_results = {}\n",
    "    \n",
    "        for topic, sentence in sentences_dict.items():\n",
    "            print(f'\\n{topic.capitalize()}:')\n",
    "        \n",
    "            preds = model(sentence, top_k = k)\n",
    "\n",
    "            words_dict = {f'word_{idx + 1}': pred['token_str'] for idx, pred in enumerate(preds)}\n",
    "            scores_dict = {f'score_{idx + 1}': pred['score'] for idx, pred in enumerate(preds)}\n",
    "            model_results[topic] = dict(itertools.chain(*zip(words_dict.items(), scores_dict.items())))\n",
    "        \n",
    "            print(sentence.replace('<mask>', colored('<mask>', 'red')))\n",
    "            print(preds[0]['sequence'].replace(preds[0]['token_str'], colored(preds[0]['token_str'], 'green')))\n",
    "        \n",
    "        display(pd.DataFrame.from_dict(model_results, orient = 'index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b780f9fc-e99d-4169-a100-820cc00e256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [twhin_bert_fill_mask, herbert_base_fill_mask, xlm_roberta_fill_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e006037b-7c36-4f72-8d08-8a9458868647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: twhin-bert-base\n",
      "---------------------------------------------\n",
      "\n",
      "Nominative:\n",
      "Warszawa to największe \u001b[31m<mask>\u001b[0m.\n",
      "Warszawa to największe \u001b[32mmiasto\u001b[0m .\n",
      "\n",
      "Genitive:\n",
      "Brakuje mi smaku słodkiego \u001b[31m<mask>\u001b[0m w mojej herbacie.\n",
      "Brakuje mi smaku słodkiego\u001b[32m,\u001b[0m w mojej herbacie.\n",
      "\n",
      "Dative:\n",
      "Daję napiwek uprzejmemu \u001b[31m<mask>\u001b[0m w restauracji.\n",
      "Daję napiwek uprzejmemu \u001b[32mdzisiaj\u001b[0m w restauracji.\n",
      "\n",
      "Accusative:\n",
      "Zbudowałem mały \u001b[31m<mask>\u001b[0m na plaży.\n",
      "Zbudowałem mały \u001b[32mdom\u001b[0m na plaży.\n",
      "\n",
      "Instrumental:\n",
      "Piszę nowym \u001b[31m<mask>\u001b[0m, który wczoraj kupiłem.\n",
      "Piszę nowym \u001b[32malbum\u001b[0m , który wczoraj kupiłem.\n",
      "\n",
      "Locative:\n",
      "Czytałem o ciekawym \u001b[31m<mask>\u001b[0m w gazecie.\n",
      "Czytałem o ciekawym \u001b[32mrynku\u001b[0m w gazecie.\n",
      "\n",
      "Vocative:\n",
      "Mądry \u001b[31m<mask>\u001b[0m, wysłuchaj moich słów!\n",
      "Mądry \u001b[32mBoże\u001b[0m , wysłuchaj moich słów!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nominative</th>\n",
       "      <td>miasto</td>\n",
       "      <td>0.736737</td>\n",
       "      <td>miasta</td>\n",
       "      <td>0.054660</td>\n",
       "      <td>miejsce</td>\n",
       "      <td>0.032278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genitive</th>\n",
       "      <td>,</td>\n",
       "      <td>0.074094</td>\n",
       "      <td>kota</td>\n",
       "      <td>0.048996</td>\n",
       "      <td>mleka</td>\n",
       "      <td>0.037487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dative</th>\n",
       "      <td>dzisiaj</td>\n",
       "      <td>0.068017</td>\n",
       "      <td>dziś</td>\n",
       "      <td>0.054846</td>\n",
       "      <td>jak</td>\n",
       "      <td>0.046457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accusative</th>\n",
       "      <td>dom</td>\n",
       "      <td>0.146561</td>\n",
       "      <td>stadion</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>samochód</td>\n",
       "      <td>0.025140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumental</th>\n",
       "      <td>album</td>\n",
       "      <td>0.310780</td>\n",
       "      <td>książkę</td>\n",
       "      <td>0.044605</td>\n",
       "      <td>telefon</td>\n",
       "      <td>0.036752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locative</th>\n",
       "      <td>rynku</td>\n",
       "      <td>0.283439</td>\n",
       "      <td>świecie</td>\n",
       "      <td>0.071885</td>\n",
       "      <td>portalu</td>\n",
       "      <td>0.041350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocative</th>\n",
       "      <td>Boże</td>\n",
       "      <td>0.247848</td>\n",
       "      <td>człowiek</td>\n",
       "      <td>0.055606</td>\n",
       "      <td>Putin</td>\n",
       "      <td>0.015251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_1   score_1    word_2   score_2    word_3   score_3\n",
       "nominative     miasto  0.736737    miasta  0.054660   miejsce  0.032278\n",
       "genitive            ,  0.074094      kota  0.048996     mleka  0.037487\n",
       "dative        dzisiaj  0.068017      dziś  0.054846       jak  0.046457\n",
       "accusative        dom  0.146561   stadion  0.052840  samochód  0.025140\n",
       "instrumental    album  0.310780   książkę  0.044605   telefon  0.036752\n",
       "locative        rynku  0.283439   świecie  0.071885   portalu  0.041350\n",
       "vocative         Boże  0.247848  człowiek  0.055606     Putin  0.015251"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: herbert-base-cased\n",
      "---------------------------------------------\n",
      "\n",
      "Nominative:\n",
      "Warszawa to największe \u001b[31m<mask>\u001b[0m.\n",
      "Warszawa to największe \u001b[32mmiasto\u001b[0m .\n",
      "\n",
      "Genitive:\n",
      "Brakuje mi smaku słodkiego \u001b[31m<mask>\u001b[0m w mojej herbacie.\n",
      "Brakuje mi smaku słodkiego \u001b[32mmleka\u001b[0m w mojej herbacie .\n",
      "\n",
      "Dative:\n",
      "Daję napiwek uprzejmemu \u001b[31m<mask>\u001b[0m w restauracji.\n",
      "Daję napiwek uprzejmemu \u001b[32mklientowi\u001b[0m w restauracji .\n",
      "\n",
      "Accusative:\n",
      "Zbudowałem mały \u001b[31m<mask>\u001b[0m na plaży.\n",
      "Zbudowałem mały \u001b[32mdomek\u001b[0m na plaży .\n",
      "\n",
      "Instrumental:\n",
      "Piszę nowym \u001b[31m<mask>\u001b[0m, który wczoraj kupiłem.\n",
      "Piszę nowym \u001b[32mtekstem\u001b[0m , który wczoraj kupiłem .\n",
      "\n",
      "Locative:\n",
      "Czytałem o ciekawym \u001b[31m<mask>\u001b[0m w gazecie.\n",
      "Czytałem o ciekawym \u001b[32martykule\u001b[0m w gazecie .\n",
      "\n",
      "Vocative:\n",
      "Mądry \u001b[31m<mask>\u001b[0m, wysłuchaj moich słów!\n",
      "Mądry \u001b[32mczłowieku\u001b[0m , wysłuchaj moich słów !\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nominative</th>\n",
       "      <td>miasto</td>\n",
       "      <td>0.810391</td>\n",
       "      <td>lotnisko</td>\n",
       "      <td>0.082490</td>\n",
       "      <td>centrum</td>\n",
       "      <td>0.026521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genitive</th>\n",
       "      <td>mleka</td>\n",
       "      <td>0.133326</td>\n",
       "      <td>cukru</td>\n",
       "      <td>0.128373</td>\n",
       "      <td>miodu</td>\n",
       "      <td>0.119054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dative</th>\n",
       "      <td>klientowi</td>\n",
       "      <td>0.307106</td>\n",
       "      <td>koledze</td>\n",
       "      <td>0.224259</td>\n",
       "      <td>panu</td>\n",
       "      <td>0.175446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accusative</th>\n",
       "      <td>domek</td>\n",
       "      <td>0.589590</td>\n",
       "      <td>ogródek</td>\n",
       "      <td>0.105919</td>\n",
       "      <td>ogród</td>\n",
       "      <td>0.047390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumental</th>\n",
       "      <td>tekstem</td>\n",
       "      <td>0.315495</td>\n",
       "      <td>artykułem</td>\n",
       "      <td>0.158764</td>\n",
       "      <td>artykule</td>\n",
       "      <td>0.030858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locative</th>\n",
       "      <td>artykule</td>\n",
       "      <td>0.637309</td>\n",
       "      <td>temacie</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>miejscu</td>\n",
       "      <td>0.045275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocative</th>\n",
       "      <td>człowieku</td>\n",
       "      <td>0.529148</td>\n",
       "      <td>Polak</td>\n",
       "      <td>0.079474</td>\n",
       "      <td>jesteś</td>\n",
       "      <td>0.060546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word_1   score_1     word_2   score_2    word_3   score_3\n",
       "nominative       miasto  0.810391   lotnisko  0.082490   centrum  0.026521\n",
       "genitive          mleka  0.133326      cukru  0.128373     miodu  0.119054\n",
       "dative        klientowi  0.307106    koledze  0.224259      panu  0.175446\n",
       "accusative        domek  0.589590    ogródek  0.105919     ogród  0.047390\n",
       "instrumental    tekstem  0.315495  artykułem  0.158764  artykule  0.030858\n",
       "locative       artykule  0.637309    temacie  0.069565   miejscu  0.045275\n",
       "vocative      człowieku  0.529148      Polak  0.079474    jesteś  0.060546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: xlm-roberta-base\n",
      "---------------------------------------------\n",
      "\n",
      "Nominative:\n",
      "Warszawa to największe \u001b[31m<mask>\u001b[0m.\n",
      "Warszawa to największe \u001b[32mmiasto\u001b[0m .\n",
      "\n",
      "Genitive:\n",
      "Brakuje mi smaku słodkiego \u001b[31m<mask>\u001b[0m w mojej herbacie.\n",
      "Brakuje mi smaku słodkiego \u001b[32mcukru\u001b[0m w mojej herbacie.\n",
      "\n",
      "Dative:\n",
      "Daję napiwek uprzejmemu \u001b[31m<mask>\u001b[0m w restauracji.\n",
      "Daję napiwek uprzejmemu\u001b[32m,\u001b[0m w restauracji.\n",
      "\n",
      "Accusative:\n",
      "Zbudowałem mały \u001b[31m<mask>\u001b[0m na plaży.\n",
      "Zbudowałem mały \u001b[32mdom\u001b[0m na plaży.\n",
      "\n",
      "Instrumental:\n",
      "Piszę nowym \u001b[31m<mask>\u001b[0m, który wczoraj kupiłem.\n",
      "Piszę nowym \u001b[32mblogu\u001b[0m , który wczoraj kupiłem.\n",
      "\n",
      "Locative:\n",
      "Czytałem o ciekawym \u001b[31m<mask>\u001b[0m w gazecie.\n",
      "Czytałem o ciekawym \u001b[32martykule\u001b[0m w gazecie.\n",
      "\n",
      "Vocative:\n",
      "Mądry \u001b[31m<mask>\u001b[0m, wysłuchaj moich słów!\n",
      "Mądry \u001b[32mBoże\u001b[0m , wysłuchaj moich słów!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nominative</th>\n",
       "      <td>miasto</td>\n",
       "      <td>0.525982</td>\n",
       "      <td>miasta</td>\n",
       "      <td>0.050481</td>\n",
       "      <td></td>\n",
       "      <td>0.023420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genitive</th>\n",
       "      <td>cukru</td>\n",
       "      <td>0.271794</td>\n",
       "      <td>alkoholu</td>\n",
       "      <td>0.165072</td>\n",
       "      <td>mleka</td>\n",
       "      <td>0.074708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dative</th>\n",
       "      <td>,</td>\n",
       "      <td>0.132466</td>\n",
       "      <td>i</td>\n",
       "      <td>0.101560</td>\n",
       "      <td>gości</td>\n",
       "      <td>0.072060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accusative</th>\n",
       "      <td>dom</td>\n",
       "      <td>0.627250</td>\n",
       "      <td>sklep</td>\n",
       "      <td>0.075990</td>\n",
       "      <td>hotel</td>\n",
       "      <td>0.059166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumental</th>\n",
       "      <td>blogu</td>\n",
       "      <td>0.160931</td>\n",
       "      <td>telefonu</td>\n",
       "      <td>0.097599</td>\n",
       "      <td>samochodem</td>\n",
       "      <td>0.075135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locative</th>\n",
       "      <td>artykule</td>\n",
       "      <td>0.405312</td>\n",
       "      <td>spotkaniu</td>\n",
       "      <td>0.164633</td>\n",
       "      <td>konkursie</td>\n",
       "      <td>0.084068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocative</th>\n",
       "      <td>Boże</td>\n",
       "      <td>0.296490</td>\n",
       "      <td>człowiek</td>\n",
       "      <td>0.067605</td>\n",
       "      <td>mój</td>\n",
       "      <td>0.043820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word_1   score_1     word_2   score_2      word_3   score_3\n",
       "nominative      miasto  0.525982     miasta  0.050481              0.023420\n",
       "genitive         cukru  0.271794   alkoholu  0.165072       mleka  0.074708\n",
       "dative               ,  0.132466          i  0.101560       gości  0.072060\n",
       "accusative         dom  0.627250      sklep  0.075990       hotel  0.059166\n",
       "instrumental     blogu  0.160931   telefonu  0.097599  samochodem  0.075135\n",
       "locative      artykule  0.405312  spotkaniu  0.164633   konkursie  0.084068\n",
       "vocative          Boże  0.296490   człowiek  0.067605         mój  0.043820"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_models_topic_understanding(model_list, polish_cases_sentences_dict, k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2630ecbb-160d-4ccb-8183-b3197bf794ea",
   "metadata": {},
   "source": [
    "I am going to analyse model understanding of Polish cases one by one:\n",
    "- **nominative** - All tested models correctly completed the nominative case with 'miasto',\n",
    "- **genitive** - the best results were obtained for 'mleko' with twhin-bert-base and 'cukru' with xlm-roberta-base. The herbert-base-cased model found ',' indicating the lack of a matching word,\n",
    "- **dative** - all models failed to find an appropriate matching word,\n",
    "- **accusative** - the xlm-roberta-base model performed best in the accusative, correctly selecting 'dom'. The herbert-base-cased model also had sensible answer 'domek', but with slightly worse fit,\n",
    "- **instrumental** - all models failed to find an appropriate matching word,\n",
    "- **locative** - all models found matching words, but I would not say these matchings were the best,\n",
    "- **vocative** - the herbert-base-cased model achieved the best result with the answer 'człowieku'. Other models returned not such obvious results but still acceptable\n",
    "\n",
    "Summarising results of an analysis, tested models do not understand all Polish cases. The biggest problems occured in : genitive, dative and instrumental. In contrast all models searched nominative quite well (even second word options were mostly close to an appropriate word)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2ee20-f606-44cc-ab3c-a23b714258b7",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700b40d-23d7-4271-a386-268e9bb20dc1",
   "metadata": {},
   "source": [
    "Devise a method to test long-range relationships such as gender. E.e. you can use two verbs with masculine and feminine gender, where one of the verbs is masked. Both verbs should have the same gender, assuming the subject is the same. Define at least 3 such sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4062a971-0001-4fe0-ad3e-fed3f393e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_sentences_dict = {\n",
    "    'masculine_1': 'Mężczyzna wziął arbuz do ręki i <mask> go na kawałki.',\n",
    "    'masculine_2': 'On najpierw zbudował model statku, a następnie <mask> mu zdjęcie.',\n",
    "    'masculine_3': 'Programista <mask> nowy program, po czym pochwalił się nim w internecie.',\n",
    "    'feminine_1': 'Dziewczyna weszła do piekarni i <mask> bułki na śniadanie.',\n",
    "    'feminine_2': 'Ona kupiła gorącą kawę, a następnie ją <mask>.',\n",
    "    'feminine_3': 'Siostra zapakowała prezent w kolorowy papier i <mask> go do torby.'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f57b33f6-1ebe-4430-a10b-3da7d45f7554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: twhin-bert-base\n",
      "---------------------------------------------\n",
      "\n",
      "Masculine_1:\n",
      "Mężczyzna wziął arbuz do ręki i \u001b[31m<mask>\u001b[0m go na kawałki.\n",
      "Mężczyzna wziął arbuz do ręki i \u001b[32mtrafił\u001b[0m go na kawałki.\n",
      "\n",
      "Masculine_2:\n",
      "On najpierw zbudował model statku, a następnie \u001b[31m<mask>\u001b[0m mu zdjęcie.\n",
      "On najpierw zbudował model statku, a następnie \u001b[32mzrobił\u001b[0m mu zdjęcie.\n",
      "\n",
      "Masculine_3:\n",
      "Programista \u001b[31m<mask>\u001b[0m nowy program, po czym pochwalił się nim w internecie.\n",
      "Programista \u001b[32mstworzył\u001b[0m nowy program, po czym pochwalił się nim w internecie.\n",
      "\n",
      "Feminine_1:\n",
      "Dziewczyna weszła do piekarni i \u001b[31m<mask>\u001b[0m bułki na śniadanie.\n",
      "Dziewczyna weszła do piekarni i \u001b[32mkupił\u001b[0m bułki na śniadanie.\n",
      "\n",
      "Feminine_2:\n",
      "Ona kupiła gorącą kawę, a następnie ją \u001b[31m<mask>\u001b[0m.\n",
      "Ona \u001b[32mkupił\u001b[0ma gorącą kawę, a następnie ją \u001b[32mkupił\u001b[0m .\n",
      "\n",
      "Feminine_3:\n",
      "Siostra zapakowała prezent w kolorowy papier i \u001b[31m<mask>\u001b[0m go do torby.\n",
      "Siostra zapakowała prezent w kolorowy papier i \u001b[32mkupił\u001b[0m go do torby.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>masculine_1</th>\n",
       "      <td>trafił</td>\n",
       "      <td>0.165227</td>\n",
       "      <td>zmienił</td>\n",
       "      <td>0.097366</td>\n",
       "      <td>wpadł</td>\n",
       "      <td>0.071723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masculine_2</th>\n",
       "      <td>zrobił</td>\n",
       "      <td>0.699268</td>\n",
       "      <td>pokazał</td>\n",
       "      <td>0.084741</td>\n",
       "      <td>kupił</td>\n",
       "      <td>0.035828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masculine_3</th>\n",
       "      <td>stworzył</td>\n",
       "      <td>0.220869</td>\n",
       "      <td>miał</td>\n",
       "      <td>0.139517</td>\n",
       "      <td>zrobił</td>\n",
       "      <td>0.107221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminine_1</th>\n",
       "      <td>kupił</td>\n",
       "      <td>0.244010</td>\n",
       "      <td>robi</td>\n",
       "      <td>0.169651</td>\n",
       "      <td>zrobił</td>\n",
       "      <td>0.067073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminine_2</th>\n",
       "      <td>kupił</td>\n",
       "      <td>0.142151</td>\n",
       "      <td>pije</td>\n",
       "      <td>0.050519</td>\n",
       "      <td>zaczęła</td>\n",
       "      <td>0.030119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminine_3</th>\n",
       "      <td>kupił</td>\n",
       "      <td>0.083535</td>\n",
       "      <td>dostala</td>\n",
       "      <td>0.074910</td>\n",
       "      <td>chciała</td>\n",
       "      <td>0.056530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_1   score_1   word_2   score_2   word_3   score_3\n",
       "masculine_1    trafił  0.165227  zmienił  0.097366    wpadł  0.071723\n",
       "masculine_2    zrobił  0.699268  pokazał  0.084741    kupił  0.035828\n",
       "masculine_3  stworzył  0.220869     miał  0.139517   zrobił  0.107221\n",
       "feminine_1      kupił  0.244010     robi  0.169651   zrobił  0.067073\n",
       "feminine_2      kupił  0.142151     pije  0.050519  zaczęła  0.030119\n",
       "feminine_3      kupił  0.083535  dostala  0.074910  chciała  0.056530"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: herbert-base-cased\n",
      "---------------------------------------------\n",
      "\n",
      "Masculine_1:\n",
      "Mężczyzna wziął arbuz do ręki i \u001b[31m<mask>\u001b[0m go na kawałki.\n",
      "Mężczyzna wziął arbuz do ręki i \u001b[32mpodzielił\u001b[0m go na kawałki .\n",
      "\n",
      "Masculine_2:\n",
      "On najpierw zbudował model statku, a następnie \u001b[31m<mask>\u001b[0m mu zdjęcie.\n",
      "On najpierw zbudował model statku , a następnie \u001b[32mzrobił\u001b[0m mu zdjęcie .\n",
      "\n",
      "Masculine_3:\n",
      "Programista \u001b[31m<mask>\u001b[0m nowy program, po czym pochwalił się nim w internecie.\n",
      "Programista \u001b[32mstworzył\u001b[0m nowy program , po czym pochwalił się nim w internecie .\n",
      "\n",
      "Feminine_1:\n",
      "Dziewczyna weszła do piekarni i \u001b[31m<mask>\u001b[0m bułki na śniadanie.\n",
      "Dziewczyna weszła do piekarni i \u001b[32mprzyniosła\u001b[0m bułki na śniadanie .\n",
      "\n",
      "Feminine_2:\n",
      "Ona kupiła gorącą kawę, a następnie ją \u001b[31m<mask>\u001b[0m.\n",
      "Ona kupiła gorącą kawę , a następnie ją \u001b[32mprzyniosła\u001b[0m .\n",
      "\n",
      "Feminine_3:\n",
      "Siostra zapakowała prezent w kolorowy papier i \u001b[31m<mask>\u001b[0m go do torby.\n",
      "Siostra zapakowała prezent w kolorowy papier i \u001b[32mprzyniosła\u001b[0m go do torby .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>masculine_1</th>\n",
       "      <td>podzielił</td>\n",
       "      <td>0.385333</td>\n",
       "      <td>rozbił</td>\n",
       "      <td>0.129012</td>\n",
       "      <td>złamał</td>\n",
       "      <td>0.039373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masculine_2</th>\n",
       "      <td>zrobił</td>\n",
       "      <td>0.773811</td>\n",
       "      <td>wykonał</td>\n",
       "      <td>0.102137</td>\n",
       "      <td>robił</td>\n",
       "      <td>0.032378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masculine_3</th>\n",
       "      <td>stworzył</td>\n",
       "      <td>0.307816</td>\n",
       "      <td>opracował</td>\n",
       "      <td>0.113065</td>\n",
       "      <td>przygotował</td>\n",
       "      <td>0.095846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminine_1</th>\n",
       "      <td>przyniosła</td>\n",
       "      <td>0.676425</td>\n",
       "      <td>kupiła</td>\n",
       "      <td>0.117508</td>\n",
       "      <td>zrobiła</td>\n",
       "      <td>0.032191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminine_2</th>\n",
       "      <td>przyniosła</td>\n",
       "      <td>0.209883</td>\n",
       "      <td>kupiła</td>\n",
       "      <td>0.103914</td>\n",
       "      <td>podała</td>\n",
       "      <td>0.072724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminine_3</th>\n",
       "      <td>przyniosła</td>\n",
       "      <td>0.196058</td>\n",
       "      <td>zabrała</td>\n",
       "      <td>0.190756</td>\n",
       "      <td>wniosła</td>\n",
       "      <td>0.083803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word_1   score_1     word_2   score_2       word_3   score_3\n",
       "masculine_1   podzielił  0.385333     rozbił  0.129012       złamał  0.039373\n",
       "masculine_2      zrobił  0.773811    wykonał  0.102137        robił  0.032378\n",
       "masculine_3    stworzył  0.307816  opracował  0.113065  przygotował  0.095846\n",
       "feminine_1   przyniosła  0.676425     kupiła  0.117508      zrobiła  0.032191\n",
       "feminine_2   przyniosła  0.209883     kupiła  0.103914       podała  0.072724\n",
       "feminine_3   przyniosła  0.196058    zabrała  0.190756      wniosła  0.083803"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: xlm-roberta-base\n",
      "---------------------------------------------\n",
      "\n",
      "Masculine_1:\n",
      "Mężczyzna wziął arbuz do ręki i \u001b[31m<mask>\u001b[0m go na kawałki.\n",
      "Mężczyzna wziął arbuz do ręki i \u001b[32mzrobił\u001b[0m go na kawałki.\n",
      "\n",
      "Masculine_2:\n",
      "On najpierw zbudował model statku, a następnie \u001b[31m<mask>\u001b[0m mu zdjęcie.\n",
      "On najpierw zbudował model statku, a następnie \u001b[32mzrobił\u001b[0m mu zdjęcie.\n",
      "\n",
      "Masculine_3:\n",
      "Programista \u001b[31m<mask>\u001b[0m nowy program, po czym pochwalił się nim w internecie.\n",
      "Programista \u001b[32mstworzył\u001b[0m nowy program, po czym pochwalił się nim w internecie.\n",
      "\n",
      "Feminine_1:\n",
      "Dziewczyna weszła do piekarni i \u001b[31m<mask>\u001b[0m bułki na śniadanie.\n",
      "Dziewczyna weszła do piekarni i \u001b[32mdala\u001b[0m bułki na śniadanie.\n",
      "\n",
      "Feminine_2:\n",
      "Ona kupiła gorącą kawę, a następnie ją \u001b[31m<mask>\u001b[0m.\n",
      "Ona kupiła gorącą kawę, a następnie ją \u001b[32mpije\u001b[0m .\n",
      "\n",
      "Feminine_3:\n",
      "Siostra zapakowała prezent w kolorowy papier i \u001b[31m<mask>\u001b[0m go do torby.\n",
      "Siostra zapakowała prezent w kolorowy papier i \u001b[32mdala\u001b[0m go do torby.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>masculine_1</th>\n",
       "      <td>zrobił</td>\n",
       "      <td>0.298887</td>\n",
       "      <td>dal</td>\n",
       "      <td>0.185793</td>\n",
       "      <td>ł</td>\n",
       "      <td>0.041491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masculine_2</th>\n",
       "      <td>zrobił</td>\n",
       "      <td>0.703186</td>\n",
       "      <td>pokazał</td>\n",
       "      <td>0.129618</td>\n",
       "      <td>stworzył</td>\n",
       "      <td>0.036255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masculine_3</th>\n",
       "      <td>stworzył</td>\n",
       "      <td>0.551055</td>\n",
       "      <td>napisał</td>\n",
       "      <td>0.179630</td>\n",
       "      <td>rozpoczął</td>\n",
       "      <td>0.048421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminine_1</th>\n",
       "      <td>dala</td>\n",
       "      <td>0.319552</td>\n",
       "      <td>pani</td>\n",
       "      <td>0.224230</td>\n",
       "      <td>robi</td>\n",
       "      <td>0.074098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminine_2</th>\n",
       "      <td>pije</td>\n",
       "      <td>0.392522</td>\n",
       "      <td>spala</td>\n",
       "      <td>0.080102</td>\n",
       "      <td>kupił</td>\n",
       "      <td>0.037110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feminine_3</th>\n",
       "      <td>dala</td>\n",
       "      <td>0.921451</td>\n",
       "      <td>doda</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>dodaje</td>\n",
       "      <td>0.009135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_1   score_1   word_2   score_2     word_3   score_3\n",
       "masculine_1    zrobił  0.298887      dal  0.185793          ł  0.041491\n",
       "masculine_2    zrobił  0.703186  pokazał  0.129618   stworzył  0.036255\n",
       "masculine_3  stworzył  0.551055  napisał  0.179630  rozpoczął  0.048421\n",
       "feminine_1       dala  0.319552     pani  0.224230       robi  0.074098\n",
       "feminine_2       pije  0.392522    spala  0.080102      kupił  0.037110\n",
       "feminine_3       dala  0.921451     doda  0.016736     dodaje  0.009135"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_models_topic_understanding(model_list, gender_sentences_dict, k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab6836-ccd6-45be-b4b9-8767ed61fa36",
   "metadata": {},
   "source": [
    "I am going to analyse model one by one in order to check if they understand a long-range relationships such as gender:\n",
    "- **masculine_1** - all models suggested masculine words. However only herbert-base-cased found an appropriate word for the sentence.\n",
    "- **masculine_2** - all models proper masculine words. The second found word returned by herbert-base-cased model was also good option for this sentence,\n",
    "- **masculine_3** - all models returned appropaite masculine words in the rank,\n",
    "- **feminine_1** - only one model herbert-base-cased managed to return fittiing feminine word. A xlm-roberta-base even returned unknown word 'dala'.\n",
    "- **feminine_2** - in my opion only herbert-base-cased model suggested fitting word 'przyniosła'. Other models failed, particularly twhin-bert-base , which returned 'kupił' for feminine word,\n",
    "- **feminine_3** - the only successfull model in this case was herbert-base-cased, which suggested przyniosła (it is not top option , but I accept it). Other models failed inluding xlm-roberta-base model, which returned unknown word 'dala'.\n",
    "\n",
    "Having insight into obtained results I can conclude that the herbert-base-cased model showed the best overall understanding of gender in sentences. This model correctly handled both masculine and feminine contexts. In contrast, xlm-roberta-base and twhin-bert-base models faced issues, particularly in feminine contexts, failing to return correct gendered words in several instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c07e0-63cc-4e23-a41c-ccbf66c4e0e8",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4314b64b-f725-4ae1-b34b-66db465ed1af",
   "metadata": {},
   "source": [
    "Check if the model captures real-world knolwedge. For instance a sentence \"`[MASK]` wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\" checks if the model \"knows\" the description of water. Define at least 3 such sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd2a92bf-26e8-45a0-abce-a5ec303ddce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_world_knowledge_dict = {\n",
    "    'sentence_1': 'Ziemia jest trzecią <mask> w Układzie Słonecznym.',\n",
    "    'sentence_2': 'Woda składa się z dwóch atomów wodoru i jednego atomu <mask>.',\n",
    "    'sentence_3': 'Największym kontynentem na świecie jest <mask>.',\n",
    "    'sentence_4': 'Największą prędkość we Wszechświecie osiąga <mask>.',\n",
    "    'sentence_5': 'Mount Everest jest najwyższą <mask> na Ziemi.'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffd9fbc5-2890-493e-a4b4-07f09819446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: twhin-bert-base\n",
      "---------------------------------------------\n",
      "\n",
      "Sentence_1:\n",
      "Ziemia jest trzecią \u001b[31m<mask>\u001b[0m w Układzie Słonecznym.\n",
      "Ziemia jest trzecią \u001b[32mosobą\u001b[0m w Układzie Słonecznym.\n",
      "\n",
      "Sentence_2:\n",
      "Woda składa się z dwóch atomów wodoru i jednego atomu \u001b[31m<mask>\u001b[0m.\n",
      "Woda składa się z dwóch atomów wodoru i jednego atomu \u001b[32mputin\u001b[0m .\n",
      "\n",
      "Sentence_3:\n",
      "Największym kontynentem na świecie jest \u001b[31m<mask>\u001b[0m.\n",
      "Największym kontynentem na świecie jest \u001b[32mPolska\u001b[0m .\n",
      "\n",
      "Sentence_4:\n",
      "Największą prędkość we Wszechświecie osiąga \u001b[31m<mask>\u001b[0m.\n",
      "Największą prędkość we Wszechświecie osiąga \u001b[32mBóg\u001b[0m .\n",
      "\n",
      "Sentence_5:\n",
      "Mount Everest jest najwyższą \u001b[31m<mask>\u001b[0m na Ziemi.\n",
      "Mount Everest jest najwyższą \u001b[32mosobą\u001b[0m na Ziemi.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentence_1</th>\n",
       "      <td>osobą</td>\n",
       "      <td>0.791013</td>\n",
       "      <td>miejsce</td>\n",
       "      <td>0.039414</td>\n",
       "      <td>ręką</td>\n",
       "      <td>0.015163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_2</th>\n",
       "      <td>putin</td>\n",
       "      <td>0.108221</td>\n",
       "      <td>atom</td>\n",
       "      <td>0.076849</td>\n",
       "      <td>NATO</td>\n",
       "      <td>0.052713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_3</th>\n",
       "      <td>Polska</td>\n",
       "      <td>0.101999</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>0.079794</td>\n",
       "      <td>Putin</td>\n",
       "      <td>0.075968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_4</th>\n",
       "      <td>Bóg</td>\n",
       "      <td>0.184124</td>\n",
       "      <td>Polska</td>\n",
       "      <td>0.057120</td>\n",
       "      <td>my</td>\n",
       "      <td>0.035603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_5</th>\n",
       "      <td>osobą</td>\n",
       "      <td>0.647363</td>\n",
       "      <td>częścią</td>\n",
       "      <td>0.053028</td>\n",
       "      <td>wodą</td>\n",
       "      <td>0.018888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word_1   score_1   word_2   score_2 word_3   score_3\n",
       "sentence_1   osobą  0.791013  miejsce  0.039414   ręką  0.015163\n",
       "sentence_2   putin  0.108221     atom  0.076849   NATO  0.052713\n",
       "sentence_3  Polska  0.101999  Twitter  0.079794  Putin  0.075968\n",
       "sentence_4     Bóg  0.184124   Polska  0.057120     my  0.035603\n",
       "sentence_5   osobą  0.647363  częścią  0.053028   wodą  0.018888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: herbert-base-cased\n",
      "---------------------------------------------\n",
      "\n",
      "Sentence_1:\n",
      "Ziemia jest trzecią \u001b[31m<mask>\u001b[0m w Układzie Słonecznym.\n",
      "Ziemia jest trzecią \u001b[32mgwiazdą\u001b[0m w Układzie Słonecznym .\n",
      "\n",
      "Sentence_2:\n",
      "Woda składa się z dwóch atomów wodoru i jednego atomu \u001b[31m<mask>\u001b[0m.\n",
      "Woda składa się z dwóch atomów wodoru i jednego atomu \u001b[32mtlenu\u001b[0m .\n",
      "\n",
      "Sentence_3:\n",
      "Największym kontynentem na świecie jest \u001b[31m<mask>\u001b[0m.\n",
      "Największym kontynentem na świecie jest \u001b[32mJaponia\u001b[0m .\n",
      "\n",
      "Sentence_4:\n",
      "Największą prędkość we Wszechświecie osiąga \u001b[31m<mask>\u001b[0m.\n",
      "Największą prędkość we Wszechświecie osiąga \u001b[32mSłońce\u001b[0m .\n",
      "\n",
      "Sentence_5:\n",
      "Mount Everest jest najwyższą \u001b[31m<mask>\u001b[0m na Ziemi.\n",
      "Mount Everest jest najwyższą \u001b[32mgórą\u001b[0m na Ziemi .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentence_1</th>\n",
       "      <td>gwiazdą</td>\n",
       "      <td>0.290387</td>\n",
       "      <td>planeta</td>\n",
       "      <td>0.220715</td>\n",
       "      <td>istotą</td>\n",
       "      <td>0.181981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_2</th>\n",
       "      <td>tlenu</td>\n",
       "      <td>0.383143</td>\n",
       "      <td>węgla</td>\n",
       "      <td>0.164454</td>\n",
       "      <td>siarki</td>\n",
       "      <td>0.151711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_3</th>\n",
       "      <td>Japonia</td>\n",
       "      <td>0.226761</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0.157105</td>\n",
       "      <td>Brazylia</td>\n",
       "      <td>0.088474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_4</th>\n",
       "      <td>Słońce</td>\n",
       "      <td>0.346972</td>\n",
       "      <td>Księżyc</td>\n",
       "      <td>0.116756</td>\n",
       "      <td>Ziemia</td>\n",
       "      <td>0.074622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_5</th>\n",
       "      <td>górą</td>\n",
       "      <td>0.835898</td>\n",
       "      <td>góra</td>\n",
       "      <td>0.042872</td>\n",
       "      <td>kulą</td>\n",
       "      <td>0.013952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word_1   score_1     word_2   score_2    word_3   score_3\n",
       "sentence_1  gwiazdą  0.290387    planeta  0.220715    istotą  0.181981\n",
       "sentence_2    tlenu  0.383143      węgla  0.164454    siarki  0.151711\n",
       "sentence_3  Japonia  0.226761  Australia  0.157105  Brazylia  0.088474\n",
       "sentence_4   Słońce  0.346972    Księżyc  0.116756    Ziemia  0.074622\n",
       "sentence_5     górą  0.835898       góra  0.042872      kulą  0.013952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: xlm-roberta-base\n",
      "---------------------------------------------\n",
      "\n",
      "Sentence_1:\n",
      "Ziemia jest trzecią \u001b[31m<mask>\u001b[0m w Układzie Słonecznym.\n",
      "Ziemia jest trzecią \u001b[32mosobą\u001b[0m w Układzie Słonecznym.\n",
      "\n",
      "Sentence_2:\n",
      "Woda składa się z dwóch atomów wodoru i jednego atomu \u001b[31m<mask>\u001b[0m.\n",
      "Woda składa się z dwóch atomów wodoru i jednego atomu \u001b[32mwody\u001b[0m .\n",
      "\n",
      "Sentence_3:\n",
      "Największym kontynentem na świecie jest \u001b[31m<mask>\u001b[0m.\n",
      "Największym kontynentem na świecie jest \u001b[32mKuba\u001b[0m .\n",
      "\n",
      "Sentence_4:\n",
      "Największą prędkość we Wszechświecie osiąga \u001b[31m<mask>\u001b[0m.\n",
      "Największą prędkość we Wszechświecie osiąga\u001b[32mł\u001b[0m .\n",
      "\n",
      "Sentence_5:\n",
      "Mount Everest jest najwyższą \u001b[31m<mask>\u001b[0m na Ziemi.\n",
      "Mount Everest jest najwyższą \u001b[32mwysokości\u001b[0m na Ziemi.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentence_1</th>\n",
       "      <td>osobą</td>\n",
       "      <td>0.309851</td>\n",
       "      <td>kartą</td>\n",
       "      <td>0.288977</td>\n",
       "      <td>częścią</td>\n",
       "      <td>0.135639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_2</th>\n",
       "      <td>wody</td>\n",
       "      <td>0.390897</td>\n",
       "      <td>soli</td>\n",
       "      <td>0.332214</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.034282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_3</th>\n",
       "      <td>Kuba</td>\n",
       "      <td>0.278558</td>\n",
       "      <td>Madagaskar</td>\n",
       "      <td>0.082982</td>\n",
       "      <td>India</td>\n",
       "      <td>0.036254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_4</th>\n",
       "      <td>ł</td>\n",
       "      <td>0.549325</td>\n",
       "      <td>ła</td>\n",
       "      <td>0.047669</td>\n",
       "      <td>ły</td>\n",
       "      <td>0.044128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_5</th>\n",
       "      <td>wysokości</td>\n",
       "      <td>0.331644</td>\n",
       "      <td>wodą</td>\n",
       "      <td>0.227669</td>\n",
       "      <td>częścią</td>\n",
       "      <td>0.079105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_1   score_1      word_2   score_2   word_3   score_3\n",
       "sentence_1      osobą  0.309851       kartą  0.288977  częścią  0.135639\n",
       "sentence_2       wody  0.390897        soli  0.332214       CO  0.034282\n",
       "sentence_3       Kuba  0.278558  Madagaskar  0.082982    India  0.036254\n",
       "sentence_4          ł  0.549325          ła  0.047669       ły  0.044128\n",
       "sentence_5  wysokości  0.331644        wodą  0.227669  częścią  0.079105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_models_topic_understanding(model_list, real_world_knowledge_dict, k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4564d46-6fae-493e-adc2-8bd28a6af4b1",
   "metadata": {},
   "source": [
    "I am going to analyse whether given models are capable of capturing real-world knolwedge or not:\n",
    "- **sentence_1** - all models identified wrong names demonstrating a lack of astronomical knowledge,\n",
    "- **sentence_2** - only herbert-base-cased model proved having some kind of knowledge by suggesting 'tlen' as a suitable word,\n",
    "- **sentence_3** - all models identified wrong words demonstrating a lack of geographical knowledge,\n",
    "- **sentence_4** - all models identified wrong words demonstrating a lack of knowledge about Physics,\n",
    "- **sentence_5** - only herbert-base-cased model proved having some knowledge about geography. Other models suggested wrong answers,\n",
    "\n",
    "Obtained results allow me to make a conclusion that choosen models do not capture real-world knolwedge or do it poorly. It has to be mentioned that herbert-base-cased model managed to retrun two good answers for five sentences. It gives me hope that mentioned model has some small capability of capturing  real-world knolwedge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5087f222-c955-4f58-91f2-7dca66aa7a80",
   "metadata": {},
   "source": [
    "## Task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb05ac-046b-491b-85bd-9c241abca04a",
   "metadata": {},
   "source": [
    "Check zero-shot learning capabilites of the models. Provide at least 5 sentences with different sentiment for the following scheme: \"'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie `[MASK]`\" Try different prompts, to see if they make any difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30e70418-dcba-4dec-b8e0-7d82a22326d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_dict = {\n",
    "    'prompt_1': \" Ta wypowiedź ma <mask> nacechowanie emocjonalne.\",\n",
    "    'prompt_2': \" Wypowiedź ta jest zdecydowanie <mask>.\",\n",
    "    'prompt_3': \" Zdanie to jest nacechowane <mask>.\"\n",
    "}\n",
    "\n",
    "sentiment_sentences_dict = {\n",
    "    'positive_1': \"'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!'\",\n",
    "    'positive_2': \"'Danie było idealnie przyprawione. Dobre żarcie dla każdego.'\",\n",
    "    'negative_1': \"'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!'\",\n",
    "    'negative_2': \"'Kelner był opryskliwy. Nie dostał napiwku.'\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28eb8ec8-acaa-41ee-ac32-48c18230d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Prompt:  Ta wypowiedź ma <mask> nacechowanie emocjonalne.\n",
      "---------------------------------------------\n",
      "Model: twhin-bert-base\n",
      "---------------------------------------------\n",
      "\n",
      "Positive_1:\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Ta wypowiedź ma \u001b[32mbyć\u001b[0m nacechowanie emocjonalne.\n",
      "\n",
      "Positive_2:\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Ta wypowiedź ma \u001b[32mbyć\u001b[0m nacechowanie emocjonalne.\n",
      "\n",
      "Negative_1:\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Ta wypowiedź ma \u001b[32mbyć\u001b[0m nacechowanie emocjonalne.\n",
      "\n",
      "Negative_2:\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Ta wypowiedź ma \u001b[32mbyć\u001b[0m nacechowanie emocjonalne.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive_1</th>\n",
       "      <td>być</td>\n",
       "      <td>0.081254</td>\n",
       "      <td>pełne</td>\n",
       "      <td>0.053161</td>\n",
       "      <td>takie</td>\n",
       "      <td>0.045235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive_2</th>\n",
       "      <td>być</td>\n",
       "      <td>0.094567</td>\n",
       "      <td>pełne</td>\n",
       "      <td>0.070791</td>\n",
       "      <td>swoje</td>\n",
       "      <td>0.035727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_1</th>\n",
       "      <td>być</td>\n",
       "      <td>0.194855</td>\n",
       "      <td>pełne</td>\n",
       "      <td>0.039156</td>\n",
       "      <td>swoje</td>\n",
       "      <td>0.035181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_2</th>\n",
       "      <td>być</td>\n",
       "      <td>0.110883</td>\n",
       "      <td>pełne</td>\n",
       "      <td>0.047603</td>\n",
       "      <td>jakieś</td>\n",
       "      <td>0.033008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_1   score_1 word_2   score_2  word_3   score_3\n",
       "positive_1    być  0.081254  pełne  0.053161   takie  0.045235\n",
       "positive_2    być  0.094567  pełne  0.070791   swoje  0.035727\n",
       "negative_1    być  0.194855  pełne  0.039156   swoje  0.035181\n",
       "negative_2    być  0.110883  pełne  0.047603  jakieś  0.033008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: herbert-base-cased\n",
      "---------------------------------------------\n",
      "\n",
      "Positive_1:\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "' Dawno nie czytałem tak dobrej książki . Zdecydowanie polecam każdemu ! ' Ta wypowiedź ma \u001b[32msilne\u001b[0m nacechowanie emocjonalne .\n",
      "\n",
      "Positive_2:\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "' Danie było idealnie przyprawione . Dobre żarcie dla każdego . ' Ta wypowiedź ma \u001b[32msilne\u001b[0m nacechowanie emocjonalne .\n",
      "\n",
      "Negative_1:\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "' Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy . Co za bubel ! ' Ta wypowiedź ma \u001b[32msilne\u001b[0m nacechowanie emocjonalne .\n",
      "\n",
      "Negative_2:\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "' Kelner był opryskliwy . Nie dostał napiwku . ' Ta wypowiedź ma \u001b[32msilne\u001b[0m nacechowanie emocjonalne .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive_1</th>\n",
       "      <td>silne</td>\n",
       "      <td>0.263757</td>\n",
       "      <td>duże</td>\n",
       "      <td>0.139661</td>\n",
       "      <td>mocne</td>\n",
       "      <td>0.086557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive_2</th>\n",
       "      <td>silne</td>\n",
       "      <td>0.265179</td>\n",
       "      <td>duże</td>\n",
       "      <td>0.142406</td>\n",
       "      <td>wyraźne</td>\n",
       "      <td>0.078462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_1</th>\n",
       "      <td>silne</td>\n",
       "      <td>0.274398</td>\n",
       "      <td>duże</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>wyraźne</td>\n",
       "      <td>0.064167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_2</th>\n",
       "      <td>silne</td>\n",
       "      <td>0.240431</td>\n",
       "      <td>duże</td>\n",
       "      <td>0.091154</td>\n",
       "      <td>pewne</td>\n",
       "      <td>0.085570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_1   score_1 word_2   score_2   word_3   score_3\n",
       "positive_1  silne  0.263757   duże  0.139661    mocne  0.086557\n",
       "positive_2  silne  0.265179   duże  0.142406  wyraźne  0.078462\n",
       "negative_1  silne  0.274398   duże  0.084623  wyraźne  0.064167\n",
       "negative_2  silne  0.240431   duże  0.091154    pewne  0.085570"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: xlm-roberta-base\n",
      "---------------------------------------------\n",
      "\n",
      "Positive_1:\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Ta wypowiedź ma \u001b[32mogromne\u001b[0m nacechowanie emocjonalne.\n",
      "\n",
      "Positive_2:\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Ta wypowiedź ma \u001b[32mpewne\u001b[0m nacechowanie emocjonalne.\n",
      "\n",
      "Negative_1:\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Ta wypowiedź ma \u001b[32mpewne\u001b[0m nacechowanie emocjonalne.\n",
      "\n",
      "Negative_2:\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Ta wypowiedź ma \u001b[31m<mask>\u001b[0m nacechowanie emocjonalne.\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Ta wypowiedź ma \u001b[32mpewne\u001b[0m nacechowanie emocjonalne.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive_1</th>\n",
       "      <td>ogromne</td>\n",
       "      <td>0.123799</td>\n",
       "      <td>pewne</td>\n",
       "      <td>0.114598</td>\n",
       "      <td>duże</td>\n",
       "      <td>0.092546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive_2</th>\n",
       "      <td>pewne</td>\n",
       "      <td>0.089985</td>\n",
       "      <td>ogromne</td>\n",
       "      <td>0.086338</td>\n",
       "      <td>duże</td>\n",
       "      <td>0.078992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_1</th>\n",
       "      <td>pewne</td>\n",
       "      <td>0.123149</td>\n",
       "      <td>ogromne</td>\n",
       "      <td>0.112585</td>\n",
       "      <td>poważne</td>\n",
       "      <td>0.086926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_2</th>\n",
       "      <td>pewne</td>\n",
       "      <td>0.178067</td>\n",
       "      <td>poważne</td>\n",
       "      <td>0.080070</td>\n",
       "      <td>jakieś</td>\n",
       "      <td>0.066021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word_1   score_1   word_2   score_2   word_3   score_3\n",
       "positive_1  ogromne  0.123799    pewne  0.114598     duże  0.092546\n",
       "positive_2    pewne  0.089985  ogromne  0.086338     duże  0.078992\n",
       "negative_1    pewne  0.123149  ogromne  0.112585  poważne  0.086926\n",
       "negative_2    pewne  0.178067  poważne  0.080070   jakieś  0.066021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Prompt:  Wypowiedź ta jest zdecydowanie <mask>.\n",
      "---------------------------------------------\n",
      "Model: twhin-bert-base\n",
      "---------------------------------------------\n",
      "\n",
      "Positive_1:\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Wypowiedź ta jest zdecydowanie \u001b[32mnajlepsza\u001b[0m .\n",
      "\n",
      "Positive_2:\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Wypowiedź ta jest zdecydowanie \u001b[32mnajlepsza\u001b[0m .\n",
      "\n",
      "Negative_1:\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Wypowiedź ta jest zdecydowanie \u001b[32mdobra\u001b[0m .\n",
      "\n",
      "Negative_2:\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Wypowiedź ta jest zdecydowanie \u001b[32mnajlepsza\u001b[0m .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive_1</th>\n",
       "      <td>najlepsza</td>\n",
       "      <td>0.241151</td>\n",
       "      <td>dobra</td>\n",
       "      <td>0.095460</td>\n",
       "      <td>super</td>\n",
       "      <td>0.038995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive_2</th>\n",
       "      <td>najlepsza</td>\n",
       "      <td>0.209214</td>\n",
       "      <td>dobra</td>\n",
       "      <td>0.107473</td>\n",
       "      <td>ważna</td>\n",
       "      <td>0.047060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_1</th>\n",
       "      <td>dobra</td>\n",
       "      <td>0.123908</td>\n",
       "      <td>najlepsza</td>\n",
       "      <td>0.101765</td>\n",
       "      <td>ważna</td>\n",
       "      <td>0.048860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_2</th>\n",
       "      <td>najlepsza</td>\n",
       "      <td>0.132037</td>\n",
       "      <td>dobra</td>\n",
       "      <td>0.126980</td>\n",
       "      <td>taka</td>\n",
       "      <td>0.040017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_1   score_1     word_2   score_2 word_3   score_3\n",
       "positive_1  najlepsza  0.241151      dobra  0.095460  super  0.038995\n",
       "positive_2  najlepsza  0.209214      dobra  0.107473  ważna  0.047060\n",
       "negative_1      dobra  0.123908  najlepsza  0.101765  ważna  0.048860\n",
       "negative_2  najlepsza  0.132037      dobra  0.126980   taka  0.040017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: herbert-base-cased\n",
      "---------------------------------------------\n",
      "\n",
      "Positive_1:\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "' Dawno nie czytałem tak dobrej książki . Zdecydowanie polecam każdemu ! ' Wypowiedź ta jest zdecydowanie \u001b[32mprawdziwa\u001b[0m .\n",
      "\n",
      "Positive_2:\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "' Danie było idealnie przyprawione . Dobre żarcie dla każdego . ' Wypowiedź ta jest zdecydowanie \u001b[32mprawdziwa\u001b[0m .\n",
      "\n",
      "Negative_1:\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "' Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy . Co za bubel ! ' Wypowiedź ta jest zdecydowanie \u001b[32mprawdziwa\u001b[0m .\n",
      "\n",
      "Negative_2:\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "' Kelner był opryskliwy . Nie dostał napiwku . ' Wypowiedź ta jest zdecydowanie \u001b[32mprawdziwa\u001b[0m .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive_1</th>\n",
       "      <td>prawdziwa</td>\n",
       "      <td>0.304513</td>\n",
       "      <td>słuszna</td>\n",
       "      <td>0.252408</td>\n",
       "      <td>pozytywna</td>\n",
       "      <td>0.089962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive_2</th>\n",
       "      <td>prawdziwa</td>\n",
       "      <td>0.188095</td>\n",
       "      <td>słuszna</td>\n",
       "      <td>0.152981</td>\n",
       "      <td>najlepsza</td>\n",
       "      <td>0.109255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_1</th>\n",
       "      <td>prawdziwa</td>\n",
       "      <td>0.280536</td>\n",
       "      <td>słuszna</td>\n",
       "      <td>0.255041</td>\n",
       "      <td>uzasadniona</td>\n",
       "      <td>0.103203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_2</th>\n",
       "      <td>prawdziwa</td>\n",
       "      <td>0.263516</td>\n",
       "      <td>słuszna</td>\n",
       "      <td>0.124830</td>\n",
       "      <td>uzasadniona</td>\n",
       "      <td>0.089556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_1   score_1   word_2   score_2       word_3   score_3\n",
       "positive_1  prawdziwa  0.304513  słuszna  0.252408    pozytywna  0.089962\n",
       "positive_2  prawdziwa  0.188095  słuszna  0.152981    najlepsza  0.109255\n",
       "negative_1  prawdziwa  0.280536  słuszna  0.255041  uzasadniona  0.103203\n",
       "negative_2  prawdziwa  0.263516  słuszna  0.124830  uzasadniona  0.089556"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: xlm-roberta-base\n",
      "---------------------------------------------\n",
      "\n",
      "Positive_1:\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Wypowiedź ta jest zdecydowanie \u001b[32mnajlepsza\u001b[0m .\n",
      "\n",
      "Positive_2:\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Wypowiedź ta jest zdecydowanie \u001b[32mdobra\u001b[0m .\n",
      "\n",
      "Negative_1:\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Wypowiedź ta jest zdecydowanie \u001b[32mdobra\u001b[0m .\n",
      "\n",
      "Negative_2:\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Wypowiedź ta jest zdecydowanie \u001b[31m<mask>\u001b[0m.\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Wypowiedź ta jest zdecydowanie \u001b[32mdobra\u001b[0m .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive_1</th>\n",
       "      <td>najlepsza</td>\n",
       "      <td>0.375452</td>\n",
       "      <td>dobra</td>\n",
       "      <td>0.316917</td>\n",
       "      <td>ważna</td>\n",
       "      <td>0.031725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive_2</th>\n",
       "      <td>dobra</td>\n",
       "      <td>0.468705</td>\n",
       "      <td>najlepsza</td>\n",
       "      <td>0.253808</td>\n",
       "      <td>ważna</td>\n",
       "      <td>0.023295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_1</th>\n",
       "      <td>dobra</td>\n",
       "      <td>0.108412</td>\n",
       "      <td>najlepsza</td>\n",
       "      <td>0.090243</td>\n",
       "      <td>kontra</td>\n",
       "      <td>0.061835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_2</th>\n",
       "      <td>dobra</td>\n",
       "      <td>0.165943</td>\n",
       "      <td>najlepsza</td>\n",
       "      <td>0.132313</td>\n",
       "      <td>ważna</td>\n",
       "      <td>0.059628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_1   score_1     word_2   score_2  word_3   score_3\n",
       "positive_1  najlepsza  0.375452      dobra  0.316917   ważna  0.031725\n",
       "positive_2      dobra  0.468705  najlepsza  0.253808   ważna  0.023295\n",
       "negative_1      dobra  0.108412  najlepsza  0.090243  kontra  0.061835\n",
       "negative_2      dobra  0.165943  najlepsza  0.132313   ważna  0.059628"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Prompt:  Zdanie to jest nacechowane <mask>.\n",
      "---------------------------------------------\n",
      "Model: twhin-bert-base\n",
      "---------------------------------------------\n",
      "\n",
      "Positive_1:\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "'Dawno nie czytałem tak dobrej książki\u001b[32m.\u001b[0m Zdecydowanie polecam każdemu!' Zdanie to jest nacechowane\u001b[32m.\u001b[0m \u001b[32m.\u001b[0m\n",
      "\n",
      "Positive_2:\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "'Danie było idealnie przyprawione\u001b[32m.\u001b[0m Dobre żarcie dla każdego\u001b[32m.\u001b[0m' Zdanie to jest nacechowane\u001b[32m.\u001b[0m \u001b[32m.\u001b[0m\n",
      "\n",
      "Negative_1:\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy\u001b[32m.\u001b[0m Co za bubel!' Zdanie to jest nacechowane\u001b[32m.\u001b[0m \u001b[32m.\u001b[0m\n",
      "\n",
      "Negative_2:\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "'Kelner był opryskliwy\u001b[32m.\u001b[0m Nie dostał napiwku\u001b[32m.\u001b[0m' Zdanie to jest nacechowane\u001b[32m.\u001b[0m \u001b[32m.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive_1</th>\n",
       "      <td>.</td>\n",
       "      <td>0.578062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101390</td>\n",
       "      <td>!</td>\n",
       "      <td>0.072242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive_2</th>\n",
       "      <td>.</td>\n",
       "      <td>0.722980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079567</td>\n",
       "      <td>!</td>\n",
       "      <td>0.038664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_1</th>\n",
       "      <td>.</td>\n",
       "      <td>0.537684</td>\n",
       "      <td>!</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_2</th>\n",
       "      <td>.</td>\n",
       "      <td>0.699597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081677</td>\n",
       "      <td>!</td>\n",
       "      <td>0.047167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_1   score_1 word_2   score_2 word_3   score_3\n",
       "positive_1      .  0.578062    ...  0.101390      !  0.072242\n",
       "positive_2      .  0.722980    ...  0.079567      !  0.038664\n",
       "negative_1      .  0.537684      !  0.098698    ...  0.088908\n",
       "negative_2      .  0.699597    ...  0.081677      !  0.047167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: herbert-base-cased\n",
      "---------------------------------------------\n",
      "\n",
      "Positive_1:\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "' Dawno nie czytałem tak dobrej książki . Zdecydowanie polecam każdemu ! ' Zdanie to jest nacechowane \u001b[32mpozytywnie\u001b[0m .\n",
      "\n",
      "Positive_2:\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "' Danie było idealnie przyprawione . Dobre żarcie dla każdego . ' Zdanie to jest nacechowane \u001b[32mpozytywnie\u001b[0m .\n",
      "\n",
      "Negative_1:\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "' Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy . Co za bubel ! ' Zdanie to jest nacechowane \u001b[32mnegatywnie\u001b[0m .\n",
      "\n",
      "Negative_2:\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "' Kelner był opryskliwy . Nie dostał napiwku . ' Zdanie to jest nacechowane \u001b[32mnegatywnie\u001b[0m .\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive_1</th>\n",
       "      <td>pozytywnie</td>\n",
       "      <td>0.354650</td>\n",
       "      <td>optymizmem</td>\n",
       "      <td>0.095387</td>\n",
       "      <td>emocjami</td>\n",
       "      <td>0.086818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive_2</th>\n",
       "      <td>pozytywnie</td>\n",
       "      <td>0.226392</td>\n",
       "      <td>smakiem</td>\n",
       "      <td>0.090595</td>\n",
       "      <td>emocjami</td>\n",
       "      <td>0.059493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_1</th>\n",
       "      <td>negatywnie</td>\n",
       "      <td>0.316242</td>\n",
       "      <td>pozytywnie</td>\n",
       "      <td>0.098502</td>\n",
       "      <td>emocjonalnie</td>\n",
       "      <td>0.087208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_2</th>\n",
       "      <td>negatywnie</td>\n",
       "      <td>0.229165</td>\n",
       "      <td>emocjonalnie</td>\n",
       "      <td>0.102099</td>\n",
       "      <td>pozytywnie</td>\n",
       "      <td>0.093584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word_1   score_1        word_2   score_2        word_3  \\\n",
       "positive_1  pozytywnie  0.354650    optymizmem  0.095387      emocjami   \n",
       "positive_2  pozytywnie  0.226392       smakiem  0.090595      emocjami   \n",
       "negative_1  negatywnie  0.316242    pozytywnie  0.098502  emocjonalnie   \n",
       "negative_2  negatywnie  0.229165  emocjonalnie  0.102099    pozytywnie   \n",
       "\n",
       "             score_3  \n",
       "positive_1  0.086818  \n",
       "positive_2  0.059493  \n",
       "negative_1  0.087208  \n",
       "negative_2  0.093584  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model: xlm-roberta-base\n",
      "---------------------------------------------\n",
      "\n",
      "Positive_1:\n",
      "'Dawno nie czytałem tak dobrej książki. Zdecydowanie polecam każdemu!' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "'Dawno nie czytałem tak dobrej książki\u001b[32m.\u001b[0m Zdecydowanie polecam każdemu!' Zdanie to jest nacechowane\u001b[32m.\u001b[0m \u001b[32m.\u001b[0m\n",
      "\n",
      "Positive_2:\n",
      "'Danie było idealnie przyprawione. Dobre żarcie dla każdego.' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "'Danie było idealnie przyprawione\u001b[32m.\u001b[0m Dobre żarcie dla każdego\u001b[32m.\u001b[0m' Zdanie to jest nacechowane\u001b[32m.\u001b[0m \u001b[32m.\u001b[0m\n",
      "\n",
      "Negative_1:\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy. Co za bubel!' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "'Według mnie zakupienie tego produktu było zmarnowaniem pieniędzy\u001b[32m.\u001b[0m Co za bubel!' Zdanie to jest nacechowane\u001b[32m.\u001b[0m \u001b[32m.\u001b[0m\n",
      "\n",
      "Negative_2:\n",
      "'Kelner był opryskliwy. Nie dostał napiwku.' Zdanie to jest nacechowane \u001b[31m<mask>\u001b[0m.\n",
      "'Kelner był opryskliwy\u001b[32m.\u001b[0m Nie dostał napiwku\u001b[32m.\u001b[0m' Zdanie to jest nacechowane\u001b[32m.\u001b[0m \u001b[32m.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>score_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>score_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive_1</th>\n",
       "      <td>.</td>\n",
       "      <td>0.256097</td>\n",
       "      <td>!</td>\n",
       "      <td>0.120203</td>\n",
       "      <td>:)</td>\n",
       "      <td>0.056545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive_2</th>\n",
       "      <td>.</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>przez</td>\n",
       "      <td>0.116941</td>\n",
       "      <td>wszystkim</td>\n",
       "      <td>0.027020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_1</th>\n",
       "      <td>.</td>\n",
       "      <td>0.338315</td>\n",
       "      <td>przez</td>\n",
       "      <td>0.086171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_2</th>\n",
       "      <td>.</td>\n",
       "      <td>0.528764</td>\n",
       "      <td>przez</td>\n",
       "      <td>0.068308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word_1   score_1 word_2   score_2     word_3   score_3\n",
       "positive_1      .  0.256097      !  0.120203         :)  0.056545\n",
       "positive_2      .  0.328414  przez  0.116941  wszystkim  0.027020\n",
       "negative_1      .  0.338315  przez  0.086171        ...  0.029276\n",
       "negative_2      .  0.528764  przez  0.068308        ...  0.029467"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for prompt_key, prompt in prompts_dict.items():\n",
    "    print(f\"{'-' * 45}\\nPrompt: {prompt}\")\n",
    "    \n",
    "    sentiment_sentences_copy_dict = {key: (lambda x: x + prompt)(sentence) for key, sentence in sentiment_sentences_dict.items()}\n",
    "    test_models_topic_understanding(model_list, sentiment_sentences_copy_dict, k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be363b2b-93c0-4775-8cea-d65266fada4d",
   "metadata": {},
   "source": [
    "I am going to analyse zero-shot learning capabilites of the models. <br>\n",
    "- **Prompt_1: Ta wypowiedź ma <mask> nacechowanie emocjonalne**  - all models failed to find positive and negative sentiment in every analysed sentence. It has to be mentioned that therbert-base-cased and xlm-roberta-base models match found words, which described an importance of the sentence insted of sentiment. Therefore, I assume the given propmpt was not interpeted by them as I was intended.\n",
    "- **Prompt_2:  Wypowiedź ta jest zdecydowanie <mask>** - all models failed to find positive and negative sentiment in every analysed sentence. Insteda, they found words describing quality or credibility of a given sentence.\n",
    "- **Prompt_3:  Zdanie to jest nacechowane <mask>** - only herbert-base-cased model was able to find proper sentiment for every analysed sentence. Other models failed, because they did not even returned interpretable words.\n",
    "\n",
    "Obtained results allow me to make a conclusion that chosen prompt has a gret impact on zero-shot learning capabilites of the models. Only the last prompt allowed to obtain some sensible results. In this case only herbert-base-cased model was able to find proper sentiment for every analysed sentence. Taking into account all its results I assume that in this text it has an edge over other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d634eefe-b1b4-4226-8dd5-659feca5fac5",
   "metadata": {},
   "source": [
    "## Task 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b20d1f-0ff3-403c-93db-268299c9513f",
   "metadata": {},
   "source": [
    "Take into accout the fact, that causal language models such as PapuGaPT2 or plT5, will only generate continuations of the sentenes, so the examples have to be created according to that paradigm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9353a-922a-49d9-8b2b-12c77a2720b5",
   "metadata": {},
   "source": [
    "## Task 8 - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b105ec-094e-4351-b915-819b1434d9fb",
   "metadata": {},
   "source": [
    "Answers on these question are generally a summaries of my other conclusion made in above tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31d3b8-5b9d-4a8a-b13b-63ee0cf58166",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Which of the models produced the best results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c587f7d-e2a9-4c07-933d-ad80f5b3b89e",
   "metadata": {},
   "source": [
    "In my answer, I am taking into account the overall results of all conducted tests. After examining my previous conclusions and printed suggestions, I would like to highlight the herbert-base-cased model, which, in my opinion, produced the best results among the considered models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cb2bf-33b2-435d-b026-a511f8c21152",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Was any of the models able to capture Polish grammar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e72e8-b434-46c5-9441-1f1b3817b992",
   "metadata": {},
   "source": [
    "In my opinion every model was able to partially capture Polish grammar. The biggest problems occured in capturing: genitive, dative and instrumental. In contrast all models suggested nominatives quite well. Despite occured errors I would like to outline herbert-base-cased model, because its suggestions were mostly appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d098fa-2daf-4d75-8731-b19cb347cd86",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Was any of the models able to capture long-distant relationships between the words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c0655-7342-4c3c-9a6b-2554c64c841a",
   "metadata": {},
   "source": [
    "Having insight into obtained results I can conclude that the herbert-base-cased model was able to capture long-distant relationships between the words. This model correctly handled both masculine and feminine contexts. In contrast, xlm-roberta-base and twhin-bert-base models faced issues, particularly in feminine contexts, failing to return correct verbs in several instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fa301-cb8e-407d-ba9b-9484c0a4ce63",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Was any of the models able to capture world knowledge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48e5bb-0194-4d2b-916f-2518714e7668",
   "metadata": {},
   "source": [
    "Obtained results allow me to make a conclusion that choosen models do not capture real-world knolwedge or do it poorly. It has to be mentioned that herbert-base-cased model managed to retrun two good answers for five sentences. It gives me hope that mentioned model has some small capability of capturing real-world knolwedge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923acabb-3605-45c1-997e-72486080051b",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Was any of the models good at doing zero-shot classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f100b30-5eee-4e5d-a373-af75f43bf505",
   "metadata": {},
   "source": [
    "Obtained results allow me to make a conclusion that chosen prompt has a great impact on zero-shot learning capabilites of the models. Only the last prompt allowed to obtain some sensible results. In this case only herbert-base-cased model was able to find proper sentiment for every analysed sentence. Taking into account all its results I assume that in this text it has an edge over other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7851bd97-2864-40e5-9c7d-f4c9ff6d932f",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "What are the most striking errors made by the models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00deecf2-1582-4352-aa32-ad3538cc95db",
   "metadata": {},
   "source": [
    "There are a few controversial errors that I would like to mention. First of all, the models sometimes were not able to suggest any fitting words, returning ',' or ','. There were also situations where the models returned words that do not exist, e.g., 'dala.' I was disappointed when I found out that, very often, the models were not able to capture world knowledge, e.g., they returned silly answers. Finally, there were failures in detecting whether verbs should be formed as if they were done by a woman or a man."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
